{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guyyariv/AI-Beat-Maker/blob/master/drums_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi"
      ],
      "metadata": {
        "id": "ADEY6zYWRw8S"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library"
      ],
      "metadata": {
        "id": "LB5Ifpyg7ETe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch fastai music21 pebble fluidsynth midi2audio"
      ],
      "metadata": {
        "id": "6KcI_qea7gBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from midi2audio import FluidSynth\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "WiqaZWDyEFAB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
      ],
      "metadata": {
        "id": "5DaOgaSAD_Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "from midi2audio import FluidSynth"
      ],
      "metadata": {
        "id": "oiXuSX8sEfsm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mido"
      ],
      "metadata": {
        "id": "YBnVNpDQEXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zPjy5dDIwUGY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from mido import Message, MidiFile, MidiTrack, bpm2tempo, MetaMessage\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1EBpFu9V9l",
        "outputId": "af340128-cbc7-4316-aedb-74e2d239b476"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network():\n",
        "\n",
        "    \"\"\" This function calls all other functions and trains the LSTM\"\"\"\n",
        "\n",
        "    # notes = get_notes()\n",
        "\n",
        "    with open('/content/notes_trap', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "metadata": {
        "id": "L0iFisM3wvqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"midi_drums/*.midi\"):\n",
        "        input_midi = MidiFile(file)\n",
        "\n",
        "        for t in input_midi.tracks[-1]:\n",
        "            # if 'track' in t.type:\n",
        "            #     notes.append(t.type)\n",
        "            if t.type == 'program_change':\n",
        "                notes.append(f'{t.type},{t.program},{t.time}')\n",
        "            elif t.type == 'control_change':\n",
        "                notes.append(f'{t.type},{t.value},{t.time}')\n",
        "            elif t.type == 'note_on' or t.type == 'note_off':\n",
        "                notes.append(f'{t.type},{t.note},{t.time},{t.velocity}')\n",
        "            else:\n",
        "                continue\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "    return notes"
      ],
      "metadata": {
        "id": "jqdlMguh5rzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "\n",
        "    \"\"\" Prepare the sequences which are the inputs for the LSTM \"\"\"\n",
        "\n",
        "    # sequence length should be changed after experimenting with different numbers\n",
        "    sequence_length = 30\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "metadata": {
        "id": "_VT-3w0_5w3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        1024,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.3,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(1024, return_sequences=True, recurrent_dropout=0.3,))\n",
        "    model.add(LSTM(1024))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    model.load_weights('/content/weights-improvement-17-0.2038-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zQ_B6sHY5zpm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output):\n",
        "\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "\n",
        "    filepath = \"weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    # experiment with different epoch sizes and batch sizes\n",
        "    model.fit(network_input, network_output, epochs=100, batch_size=512, callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "1QCit0E250qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_network()"
      ],
      "metadata": {
        "id": "0KacCi3e53gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(tempo=120):\n",
        "    \"\"\" Generates the midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('/content/notes_trap', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output, tempo)\n",
        "    create_wav()"
      ],
      "metadata": {
        "id": "gkmqMbBD7hu7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "\n",
        "    # map back from integers to notes\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 30\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "metadata": {
        "id": "nzLEiBF1Zo19"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(800):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = np.argmax(prediction) # numpy array of predictions\n",
        "        result = int_to_note[index] # indexing the note with the highest probability\n",
        "        prediction_output.append(result) # that note is the prediction output\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "metadata": {
        "id": "IluKwwKRZx66"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output, tempo):\n",
        "    mid = MidiFile()\n",
        "    track = MidiTrack()\n",
        "    track_meta = MidiTrack()\n",
        "    mid.tracks.append(track_meta)\n",
        "    mid.tracks.append(track)\n",
        "    track_meta.append(MetaMessage('set_tempo', tempo=bpm2tempo(tempo)))\n",
        "    track.append(Message('program_change', channel=9, program=12, time=0))\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        patterns = pattern.split(',')\n",
        "        if patterns[0] == 'program_change':\n",
        "            track.append(Message(patterns[0], channel=9, program=int(patterns[1]), time=int(patterns[2])))\n",
        "        elif patterns[0] == 'control_change':\n",
        "            track.append(Message(patterns[0], channel=9, value=int(patterns[1]), time=int(patterns[2])))\n",
        "        else:\n",
        "            track.append(Message(patterns[0], channel=9, note=int(patterns[1]), time=int(patterns[2]), velocity=int(patterns[3])))\n",
        "\n",
        "    mid.save('/content/new_drums.mid')"
      ],
      "metadata": {
        "id": "hTdqQXXSZ0R7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_wav():\n",
        "  fs = FluidSynth(sound_font='/content/808.sf2')\n",
        "  fs.midi_to_audio('/content/new_drums.mid', '/content/output.wav')"
      ],
      "metadata": {
        "id": "SRXpbOZl7812"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(tempo=105)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-vx7aPlZ3aq",
        "outputId": "5aeac576-33d0-48a9-e7ba-cc00cdd3cbfd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    }
  ]
}