{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfbmNnfYrBqici4YUOYHcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guyyariv/AI-Beat-Maker/blob/master/drums_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zPjy5dDIwUGY"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv1EBpFu9V9l",
        "outputId": "78f79969-feb2-4e64-8563-8ef094de2bdd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network():\n",
        "\n",
        "    \"\"\" This function calls all other functions and trains the LSTM\"\"\"\n",
        "\n",
        "    # notes = get_notes()\n",
        "\n",
        "    with open('/content/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "metadata": {
        "id": "L0iFisM3wvqc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes():\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"midi_drums/*.midi\"):\n",
        "        input_midi = MidiFile(file)\n",
        "\n",
        "        for t in input_midi.tracks[-1]:\n",
        "            # if 'track' in t.type:\n",
        "            #     notes.append(t.type)\n",
        "            if t.type == 'program_change':\n",
        "                notes.append(f'{t.type},{t.program},{t.time}')\n",
        "            elif t.type == 'control_change':\n",
        "                notes.append(f'{t.type},{t.value},{t.time}')\n",
        "            elif t.type == 'note_on' or t.type == 'note_off':\n",
        "                notes.append(f'{t.type},{t.note},{t.time},{t.velocity}')\n",
        "            else:\n",
        "                continue\n",
        "    with open('data/notes', 'wb') as filepath:\n",
        "        pickle.dump(notes, filepath)\n",
        "    return notes"
      ],
      "metadata": {
        "id": "jqdlMguh5rzd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "\n",
        "    \"\"\" Prepare the sequences which are the inputs for the LSTM \"\"\"\n",
        "\n",
        "    # sequence length should be changed after experimenting with different numbers\n",
        "    sequence_length = 30\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "metadata": {
        "id": "_VT-3w0_5w3K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.2,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.2,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    model.load_weights('/content/weights/weights-improvement-20-3.8037-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zQ_B6sHY5zpm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, network_input, network_output):\n",
        "\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "\n",
        "    filepath = \"weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    # experiment with different epoch sizes and batch sizes\n",
        "    model.fit(network_input, network_output, epochs=100, batch_size=512, callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "1QCit0E250qW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_network()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KacCi3e53gL",
        "outputId": "0b25b4ba-f80b-44b1-907c-c3ec94f9a0d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/100\n",
            "76/76 [==============================] - 54s 616ms/step - loss: 4.1938\n",
            "Epoch 2/100\n",
            "76/76 [==============================] - 47s 614ms/step - loss: 3.8682\n",
            "Epoch 3/100\n",
            "76/76 [==============================] - 47s 616ms/step - loss: 3.6612\n",
            "Epoch 4/100\n",
            "76/76 [==============================] - 46s 610ms/step - loss: 3.4960\n",
            "Epoch 5/100\n",
            "76/76 [==============================] - 47s 613ms/step - loss: 3.3692\n",
            "Epoch 6/100\n",
            "76/76 [==============================] - 47s 614ms/step - loss: 3.2642\n",
            "Epoch 7/100\n",
            "76/76 [==============================] - 47s 611ms/step - loss: 3.1580\n",
            "Epoch 8/100\n",
            "76/76 [==============================] - 46s 610ms/step - loss: 3.0629\n",
            "Epoch 9/100\n",
            "76/76 [==============================] - 46s 610ms/step - loss: 2.9802\n",
            "Epoch 10/100\n",
            "76/76 [==============================] - 46s 610ms/step - loss: 2.8932\n",
            "Epoch 11/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 2.8162\n",
            "Epoch 12/100\n",
            "76/76 [==============================] - 47s 612ms/step - loss: 2.7466\n",
            "Epoch 13/100\n",
            "76/76 [==============================] - 46s 606ms/step - loss: 2.6537\n",
            "Epoch 14/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 2.6039\n",
            "Epoch 15/100\n",
            "76/76 [==============================] - 46s 605ms/step - loss: 2.5272\n",
            "Epoch 16/100\n",
            "76/76 [==============================] - 46s 605ms/step - loss: 2.4565\n",
            "Epoch 17/100\n",
            "76/76 [==============================] - 46s 608ms/step - loss: 2.4127\n",
            "Epoch 18/100\n",
            "76/76 [==============================] - 47s 615ms/step - loss: 2.3451\n",
            "Epoch 19/100\n",
            "76/76 [==============================] - 47s 614ms/step - loss: 2.2779\n",
            "Epoch 20/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 2.2130\n",
            "Epoch 21/100\n",
            "76/76 [==============================] - 46s 606ms/step - loss: 2.1598\n",
            "Epoch 22/100\n",
            "76/76 [==============================] - 46s 604ms/step - loss: 2.1044\n",
            "Epoch 23/100\n",
            "76/76 [==============================] - 46s 604ms/step - loss: 2.0422\n",
            "Epoch 24/100\n",
            "76/76 [==============================] - 46s 611ms/step - loss: 1.9990\n",
            "Epoch 25/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 1.9596\n",
            "Epoch 26/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 1.9043\n",
            "Epoch 27/100\n",
            "76/76 [==============================] - 46s 605ms/step - loss: 1.8475\n",
            "Epoch 28/100\n",
            "76/76 [==============================] - 46s 603ms/step - loss: 1.7954\n",
            "Epoch 29/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 1.7595\n",
            "Epoch 30/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 1.7263\n",
            "Epoch 31/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 1.6745\n",
            "Epoch 32/100\n",
            "76/76 [==============================] - 46s 606ms/step - loss: 1.6432\n",
            "Epoch 33/100\n",
            "76/76 [==============================] - 46s 606ms/step - loss: 1.5836\n",
            "Epoch 34/100\n",
            "76/76 [==============================] - 46s 608ms/step - loss: 1.5545\n",
            "Epoch 35/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 1.5047\n",
            "Epoch 36/100\n",
            "76/76 [==============================] - 47s 614ms/step - loss: 1.4529\n",
            "Epoch 37/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 1.4283\n",
            "Epoch 38/100\n",
            "76/76 [==============================] - 46s 602ms/step - loss: 1.3871\n",
            "Epoch 39/100\n",
            "76/76 [==============================] - 46s 602ms/step - loss: 1.3595\n",
            "Epoch 40/100\n",
            "76/76 [==============================] - 46s 605ms/step - loss: 1.3283\n",
            "Epoch 41/100\n",
            "76/76 [==============================] - 46s 601ms/step - loss: 1.2862\n",
            "Epoch 42/100\n",
            "76/76 [==============================] - 45s 596ms/step - loss: 1.2547\n",
            "Epoch 43/100\n",
            "76/76 [==============================] - 46s 602ms/step - loss: 1.2413\n",
            "Epoch 44/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 1.1883\n",
            "Epoch 45/100\n",
            "76/76 [==============================] - 46s 611ms/step - loss: 1.1706\n",
            "Epoch 46/100\n",
            "76/76 [==============================] - 46s 604ms/step - loss: 1.1319\n",
            "Epoch 47/100\n",
            "76/76 [==============================] - 46s 601ms/step - loss: 1.1074\n",
            "Epoch 48/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 1.0853\n",
            "Epoch 49/100\n",
            "76/76 [==============================] - 46s 602ms/step - loss: 1.0654\n",
            "Epoch 50/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 1.0288\n",
            "Epoch 51/100\n",
            "76/76 [==============================] - 46s 603ms/step - loss: 0.9970\n",
            "Epoch 52/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.9967\n",
            "Epoch 53/100\n",
            "76/76 [==============================] - 46s 601ms/step - loss: 0.9755\n",
            "Epoch 54/100\n",
            "76/76 [==============================] - 47s 612ms/step - loss: 0.9473\n",
            "Epoch 55/100\n",
            "76/76 [==============================] - 46s 607ms/step - loss: 0.9208\n",
            "Epoch 56/100\n",
            "76/76 [==============================] - 45s 598ms/step - loss: 0.8983\n",
            "Epoch 57/100\n",
            "76/76 [==============================] - 45s 598ms/step - loss: 0.8861\n",
            "Epoch 58/100\n",
            "76/76 [==============================] - 46s 600ms/step - loss: 0.8755\n",
            "Epoch 59/100\n",
            "76/76 [==============================] - 45s 598ms/step - loss: 0.8645\n",
            "Epoch 60/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.8448\n",
            "Epoch 61/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.8135\n",
            "Epoch 62/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.7949\n",
            "Epoch 63/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.7928\n",
            "Epoch 64/100\n",
            "76/76 [==============================] - 46s 599ms/step - loss: 0.7621\n",
            "Epoch 65/100\n",
            "76/76 [==============================] - 45s 592ms/step - loss: 0.7547\n",
            "Epoch 66/100\n",
            "76/76 [==============================] - 45s 593ms/step - loss: 0.7438\n",
            "Epoch 67/100\n",
            "76/76 [==============================] - 45s 592ms/step - loss: 0.7399\n",
            "Epoch 68/100\n",
            "76/76 [==============================] - 45s 593ms/step - loss: 0.7239\n",
            "Epoch 69/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.6997\n",
            "Epoch 70/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.6806\n",
            "Epoch 71/100\n",
            "76/76 [==============================] - 45s 594ms/step - loss: 0.6669\n",
            "Epoch 72/100\n",
            "76/76 [==============================] - 45s 587ms/step - loss: 0.6675\n",
            "Epoch 73/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.6596\n",
            "Epoch 74/100\n",
            "76/76 [==============================] - 45s 593ms/step - loss: 0.6530\n",
            "Epoch 75/100\n",
            "76/76 [==============================] - 45s 594ms/step - loss: 0.6356\n",
            "Epoch 76/100\n",
            "76/76 [==============================] - 45s 592ms/step - loss: 0.6293\n",
            "Epoch 77/100\n",
            "76/76 [==============================] - 45s 596ms/step - loss: 0.6080\n",
            "Epoch 78/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.5987\n",
            "Epoch 79/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.5811\n",
            "Epoch 80/100\n",
            "76/76 [==============================] - 45s 589ms/step - loss: 0.5823\n",
            "Epoch 81/100\n",
            "76/76 [==============================] - 45s 588ms/step - loss: 0.5824\n",
            "Epoch 82/100\n",
            "76/76 [==============================] - 45s 596ms/step - loss: 0.5707\n",
            "Epoch 83/100\n",
            "76/76 [==============================] - 45s 594ms/step - loss: 0.5637\n",
            "Epoch 84/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.5535\n",
            "Epoch 85/100\n",
            "76/76 [==============================] - 46s 599ms/step - loss: 0.5431\n",
            "Epoch 86/100\n",
            "76/76 [==============================] - 45s 593ms/step - loss: 0.5333\n",
            "Epoch 87/100\n",
            "76/76 [==============================] - 45s 590ms/step - loss: 0.5362\n",
            "Epoch 88/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.5155\n",
            "Epoch 89/100\n",
            "76/76 [==============================] - 46s 610ms/step - loss: 0.5081\n",
            "Epoch 90/100\n",
            "76/76 [==============================] - 46s 606ms/step - loss: 0.5140\n",
            "Epoch 91/100\n",
            "76/76 [==============================] - 46s 603ms/step - loss: 0.5030\n",
            "Epoch 92/100\n",
            "76/76 [==============================] - 46s 601ms/step - loss: 0.4979\n",
            "Epoch 93/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.4811\n",
            "Epoch 94/100\n",
            "76/76 [==============================] - 46s 603ms/step - loss: 0.4898\n",
            "Epoch 95/100\n",
            "76/76 [==============================] - 47s 616ms/step - loss: 0.4778\n",
            "Epoch 96/100\n",
            "76/76 [==============================] - 46s 608ms/step - loss: 0.4678\n",
            "Epoch 97/100\n",
            "76/76 [==============================] - 45s 597ms/step - loss: 0.4620\n",
            "Epoch 98/100\n",
            "76/76 [==============================] - 46s 600ms/step - loss: 0.4508\n",
            "Epoch 99/100\n",
            "76/76 [==============================] - 45s 595ms/step - loss: 0.4540\n",
            "Epoch 100/100\n",
            "76/76 [==============================] - 46s 609ms/step - loss: 0.4529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "    \"\"\" Generates the midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    with open('/content/notes', 'rb') as filepath:\n",
        "        notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)"
      ],
      "metadata": {
        "id": "gkmqMbBD7hu7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "\n",
        "    # map back from integers to notes\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 30\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "metadata": {
        "id": "nzLEiBF1Zo19"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.2,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.2,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    model.load_weights('/content/weights/weights-improvement-98-0.4508-bigger.hdf5')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "-OKF8wV7ZvLO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = np.argmax(prediction) # numpy array of predictions\n",
        "        result = int_to_note[index] # indexing the note with the highest probability\n",
        "        prediction_output.append(result) # that note is the prediction output\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output"
      ],
      "metadata": {
        "id": "IluKwwKRZx66"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi(prediction_output):\n",
        "    mid = MidiFile()\n",
        "    track = MidiTrack()\n",
        "    mid.tracks.append(track)\n",
        "    track.append(Message('program_change', channel=9, program=12, time=0))\n",
        "\n",
        "    for pattern in prediction_output:\n",
        "        patterns = pattern.split(',')\n",
        "        if patterns[0] == 'program_change':\n",
        "            track.append(Message(patterns[0], channel=9, program=int(patterns[1]), time=int(patterns[2])))\n",
        "        elif patterns[0] == 'control_change':\n",
        "            track.append(Message(patterns[0], channel=9, value=int(patterns[1]), time=int(patterns[2])))\n",
        "        else:\n",
        "            track.append(Message(patterns[0], channel=9, note=int(patterns[1]), time=int(patterns[2]), velocity=int(patterns[3])))\n",
        "\n",
        "    mid.save('tal_the_king.mid')"
      ],
      "metadata": {
        "id": "hTdqQXXSZ0R7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-vx7aPlZ3aq",
        "outputId": "42ed0c99-81f7-4ce8-d66f-3f7b65701fcd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    }
  ]
}